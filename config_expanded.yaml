# Expanded LLM Configuration for comprehensive provider comparison
llm_providers:
  openai:
    default_model: "gpt-4o-mini"
    models:
      # GPT-4 models
      - "gpt-4o-mini"
      - "gpt-4o"
      - "gpt-4-turbo"
      # GPT-5 models
      - "gpt-5"
      - "gpt-5.1"
      - "gpt-5.2"
      # Additional models (if available)
      - "o1"
      - "o1-mini"
      - "o3-mini"
    temperature: 1.0
    max_tokens: 2000

  gemini:
    default_model: "gemini-2.5-flash"
    models:
      # Current Gemini models (as of Jan 2026)
      - "gemini-2.5-flash"
      - "gemini-2.5-pro"
      - "gemini-2.0-flash"
      - "gemini-2.0-flash-001"
      - "gemini-2.0-flash-exp"
    temperature: 1.0
    max_tokens: 2000

  anthropic:
    default_model: "claude-sonnet-4-20250514"
    models:
      # Current Claude models (verified working)
      - "claude-sonnet-4-20250514"      # Claude Sonnet 4
      - "claude-opus-4-5-20251101"      # Claude Opus 4.5
      - "claude-3-5-haiku-20241022"     # Claude 3.5 Haiku
      - "claude-3-haiku-20240307"       # Claude 3 Haiku
    temperature: 1.0
    max_tokens: 2000

# Pipeline Configuration
pipelines:
  one_shot:
    description: "Single prompt analysis"
    enabled: true

  chain_of_thought:
    description: "Step-by-step reasoning approach"
    enabled: true

  multi_layer:
    description: "Multi-stage analysis with LLM synthesis"
    enabled: true

  decomposed_algorithmic:
    description: "Criteria-based with algorithmic aggregation"
    enabled: true

# Analysis Configuration
analysis:
  output_format: "json"
  save_intermediate_results: true
  results_dir: "results"
